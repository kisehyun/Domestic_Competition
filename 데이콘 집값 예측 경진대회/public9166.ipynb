{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c809ab58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor, StackingRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "from ngboost import NGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.model_selection import KFold, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d68719b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "submission = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3df461db",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.iloc[:, 1:]\n",
    "test = test.iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c1f6e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[train['Garage Yr Blt'] < 2050]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc7370dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['new1'] = 2022 - train['Year Remod/Add']\n",
    "test['new1'] = 2022 - test['Year Remod/Add']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0699dad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['new2'] = np.log1p(train['1st Flr SF'] / train['Total Bsmt SF'])\n",
    "test['new2'] = np.log1p(test['1st Flr SF'] / test['Total Bsmt SF'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55bc913e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['new3'] = train['Gr Liv Area'] / train['1st Flr SF']\n",
    "test['new3'] = test['Gr Liv Area'] / test['1st Flr SF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ee12ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['EQ'] = train['Exter Qual'].map({'Ex' : 5, 'Gd' : 4, 'TA' : 3, 'Fa' : 2, 'Po' : 1})\n",
    "test['EQ'] = test['Exter Qual'].map({'Ex' : 5, 'Gd' : 4, 'TA' : 3, 'Fa' : 2, 'Po' : 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd035b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['KQ'] = train['Kitchen Qual'].map({'Ex' : 5, 'Gd' : 4, 'TA' : 3, 'Fa' : 2, 'Po' : 1})\n",
    "test['KQ'] = test['Kitchen Qual'].map({'Ex' : 5, 'Gd' : 4, 'TA' : 3, 'Fa' : 2, 'Po' : 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2955a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['BQ'] = train['Bsmt Qual'].map({'Ex' : 5, 'Gd' : 4, 'TA' : 3, 'Fa' : 2, 'Po' : 1})\n",
    "test['BQ'] = test['Bsmt Qual'].map({'Ex' : 5, 'Gd' : 4, 'TA' : 3, 'Fa' : 2, 'Po' : 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d224c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['TQ'] = train['Overall Qual'] * 0.5 + train['EQ'] * 0.3 + train['KQ'] * 0.15 + train['BQ'] * 0.05\n",
    "test['TQ'] = test['Overall Qual'] * 0.5 + test['EQ'] * 0.3 + test['KQ'] * 0.15 + test['BQ'] * 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a858111c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['Exter Qual', 'Kitchen Qual', 'Bsmt Qual']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "590ff879",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in cat_cols :\n",
    "    ord_df = train.groupby(c).target.mean().reset_index(name = f'ord_{c}')\n",
    "    train = pd.merge(train, ord_df, how = 'left')\n",
    "    test = pd.merge(test, ord_df, how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e79d8a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(cat_cols, axis = 1, inplace = True)\n",
    "test.drop(cat_cols, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "48ef064e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop(['KQ', 'EQ', 'BQ', 'Overall Qual', 'Garage Area', '1st Flr SF', 'target'], axis = 1)\n",
    "y = np.log1p(train.target)\n",
    "\n",
    "target = test[X.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bb60e3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "target.fillna(train.mean(), inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0ec2714d",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits = 10, random_state = 42, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b8d9b1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_models = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e7a6f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NMAE(true, pred) -> float:\n",
    "    mae = np.mean(np.abs(true - pred))\n",
    "    score = mae / np.mean(np.abs(true))\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0e3d9332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### 1 FOLD Training..... #####\n",
      "RandomForestRegressor Training Completed...NMAE = 0.08597747959431033\n",
      "GradientBoostingRegressor Training Completed...NMAE = 0.0816727872223358\n",
      "CatBoostRegressor Training Completed...NMAE = 0.08647790572898846\n",
      "NGBRegressor Training Completed...NMAE = 0.08775975983950367\n",
      "XGBRegressor Training Completed...NMAE = 0.092200131779733\n",
      "StackingRegressor Training Completed...NMAE = 0.08230470315960663\n",
      "\n",
      "********** When Ensemble, 1 FOLD Validation NMAE = 0.08267089459987931 **********\n",
      "\n",
      "##### 2 FOLD Training..... #####\n",
      "RandomForestRegressor Training Completed...NMAE = 0.10898326889883439\n",
      "GradientBoostingRegressor Training Completed...NMAE = 0.10155448019532137\n",
      "CatBoostRegressor Training Completed...NMAE = 0.10142747433648916\n",
      "NGBRegressor Training Completed...NMAE = 0.10252180606999126\n",
      "XGBRegressor Training Completed...NMAE = 0.11461251601968098\n",
      "StackingRegressor Training Completed...NMAE = 0.10018480583912069\n",
      "\n",
      "********** When Ensemble, 2 FOLD Validation NMAE = 0.10059748377879453 **********\n",
      "\n",
      "##### 3 FOLD Training..... #####\n",
      "RandomForestRegressor Training Completed...NMAE = 0.08887801973811543\n",
      "GradientBoostingRegressor Training Completed...NMAE = 0.0885421081684602\n",
      "CatBoostRegressor Training Completed...NMAE = 0.0843683197756529\n",
      "NGBRegressor Training Completed...NMAE = 0.08613045351836933\n",
      "XGBRegressor Training Completed...NMAE = 0.09150727631055941\n",
      "StackingRegressor Training Completed...NMAE = 0.08256612828318252\n",
      "\n",
      "********** When Ensemble, 3 FOLD Validation NMAE = 0.08258012665108837 **********\n",
      "\n",
      "##### 4 FOLD Training..... #####\n",
      "RandomForestRegressor Training Completed...NMAE = 0.10532939916386991\n",
      "GradientBoostingRegressor Training Completed...NMAE = 0.10433732973500758\n",
      "CatBoostRegressor Training Completed...NMAE = 0.0990795427478743\n",
      "NGBRegressor Training Completed...NMAE = 0.10447391419205776\n",
      "XGBRegressor Training Completed...NMAE = 0.10999918720291087\n",
      "StackingRegressor Training Completed...NMAE = 0.0996979655684113\n",
      "\n",
      "********** When Ensemble, 4 FOLD Validation NMAE = 0.09988474420219101 **********\n",
      "\n",
      "##### 5 FOLD Training..... #####\n",
      "RandomForestRegressor Training Completed...NMAE = 0.09719224809723932\n",
      "GradientBoostingRegressor Training Completed...NMAE = 0.10740758926405139\n",
      "CatBoostRegressor Training Completed...NMAE = 0.0987560485648317\n",
      "NGBRegressor Training Completed...NMAE = 0.09768433251861808\n",
      "XGBRegressor Training Completed...NMAE = 0.0993007926818826\n",
      "StackingRegressor Training Completed...NMAE = 0.09653483870645758\n",
      "\n",
      "********** When Ensemble, 5 FOLD Validation NMAE = 0.09557120661503639 **********\n",
      "\n",
      "##### 6 FOLD Training..... #####\n",
      "RandomForestRegressor Training Completed...NMAE = 0.09473849486268636\n",
      "GradientBoostingRegressor Training Completed...NMAE = 0.10112937305471612\n",
      "CatBoostRegressor Training Completed...NMAE = 0.096786657854293\n",
      "NGBRegressor Training Completed...NMAE = 0.09756784052674165\n",
      "XGBRegressor Training Completed...NMAE = 0.09406405606822509\n",
      "StackingRegressor Training Completed...NMAE = 0.09593085053449125\n",
      "\n",
      "********** When Ensemble, 6 FOLD Validation NMAE = 0.0949210012769243 **********\n",
      "\n",
      "##### 7 FOLD Training..... #####\n",
      "RandomForestRegressor Training Completed...NMAE = 0.08715411292234489\n",
      "GradientBoostingRegressor Training Completed...NMAE = 0.08847803764715087\n",
      "CatBoostRegressor Training Completed...NMAE = 0.09275863212050918\n",
      "NGBRegressor Training Completed...NMAE = 0.08615590917246371\n",
      "XGBRegressor Training Completed...NMAE = 0.0881859756765165\n",
      "StackingRegressor Training Completed...NMAE = 0.08834964874756986\n",
      "\n",
      "********** When Ensemble, 7 FOLD Validation NMAE = 0.08721623584449102 **********\n",
      "\n",
      "##### 8 FOLD Training..... #####\n",
      "RandomForestRegressor Training Completed...NMAE = 0.09410664524362598\n",
      "GradientBoostingRegressor Training Completed...NMAE = 0.10401514972069964\n",
      "CatBoostRegressor Training Completed...NMAE = 0.09093197162303286\n",
      "NGBRegressor Training Completed...NMAE = 0.09823630366916164\n",
      "XGBRegressor Training Completed...NMAE = 0.10180271384355019\n",
      "StackingRegressor Training Completed...NMAE = 0.09232776979565456\n",
      "\n",
      "********** When Ensemble, 8 FOLD Validation NMAE = 0.09221272199318617 **********\n",
      "\n",
      "##### 9 FOLD Training..... #####\n",
      "RandomForestRegressor Training Completed...NMAE = 0.0981030318796841\n",
      "GradientBoostingRegressor Training Completed...NMAE = 0.10865811426169297\n",
      "CatBoostRegressor Training Completed...NMAE = 0.10061534721366153\n",
      "NGBRegressor Training Completed...NMAE = 0.10729430363247958\n",
      "XGBRegressor Training Completed...NMAE = 0.09935268887517039\n",
      "StackingRegressor Training Completed...NMAE = 0.09759862288861308\n",
      "\n",
      "********** When Ensemble, 9 FOLD Validation NMAE = 0.09830959073106921 **********\n",
      "\n",
      "##### 10 FOLD Training..... #####\n",
      "RandomForestRegressor Training Completed...NMAE = 0.10202238950302732\n",
      "GradientBoostingRegressor Training Completed...NMAE = 0.09160271248840564\n",
      "CatBoostRegressor Training Completed...NMAE = 0.09453743305658996\n",
      "NGBRegressor Training Completed...NMAE = 0.09702653029130981\n",
      "XGBRegressor Training Completed...NMAE = 0.09932266114425671\n",
      "StackingRegressor Training Completed...NMAE = 0.09253044089034042\n",
      "\n",
      "********** When Ensemble, 10 FOLD Validation NMAE = 0.09323744272219142 **********\n",
      "\n",
      "*-*-*-*-*-*-*-*-*-Training & Prediction Done.....-*-*-*-*-*-*-*-*-*\n",
      "Result : 10 FOLD Mean of NMAE = 0.09272014484148516 & std = 0.006262776293169262\n",
      "##### Average NMAE of Each Model #####\n",
      "RandomForestRegressor = 0.0962485089903738\n",
      "CatBoostRegressor = 0.0945739333021923\n",
      "NGBRegressor = 0.09648511534306965\n",
      "GradientBoostingRegressor = 0.09773976817578414\n",
      "XGBRegressor = 0.09903479996024857\n",
      "StackingRegressor = 0.09280257744134479\n"
     ]
    }
   ],
   "source": [
    "val_nmae = []\n",
    "rf_nmae = []\n",
    "ngb_nmae = []\n",
    "xgb_nmae = []\n",
    "cb_nmae = []\n",
    "gbr_nmae = []\n",
    "sr_nmae = []\n",
    "fold_pred = np.zeros(target.shape[0])\n",
    "for n, (tr_idx, val_idx) in enumerate(kf.split(X, y)) :\n",
    "    print(f'##### {n + 1} FOLD Training..... #####')\n",
    "    \n",
    "    tr_x, tr_y = X.iloc[tr_idx], y.iloc[tr_idx]\n",
    "    val_x, val_y = X.iloc[val_idx], np.expm1(y.iloc[val_idx])\n",
    "    \n",
    "    tr_data = Pool(data = tr_x, label = tr_y)\n",
    "    val_data = Pool(data = val_x, label = val_y)\n",
    "    target_data = Pool(data = target, label = None)\n",
    "    \n",
    "    ### Setting the 6models\n",
    "    rf = RandomForestRegressor(random_state = 2022, criterion = 'mae')\n",
    "    cb = CatBoostRegressor(depth = 4, random_state = 2, loss_function = 'MAE', n_estimators = 2000, learning_rate = 0.03, verbose = 0)\n",
    "    ngb = NGBRegressor(random_state = 1, n_estimators = 3000, verbose = 0, learning_rate = 0.03)\n",
    "    xgb = XGBRegressor(random_state = 28, max_depth = 4, n_estimators = 3000, learning_rate = 0.03, objective = 'reg:squarederror')\n",
    "    gbr = GradientBoostingRegressor(random_state = 67, max_depth = 4, learning_rate = 0.03, n_estimators = 1500)\n",
    "    lgbm = LGBMRegressor(random_state = 42, max_depth = 4, n_estimators = 2000, learning_rate = 0.03, objective = 'l1')\n",
    "    rg = Ridge(random_state = 203)\n",
    "    \n",
    "    ### RandomForest\n",
    "    rf.fit(tr_x, tr_y)\n",
    "    rf_val = np.expm1(rf.predict(val_x))\n",
    "    rf_score = NMAE(val_y, rf_val)\n",
    "    rf_nmae.append(rf_score)\n",
    "    print(f'{rf.__class__.__name__} Training Completed...NMAE = {NMAE(val_y, rf_val)}')\n",
    "    \n",
    "    ### GradientBoosting\n",
    "    gbr.fit(tr_x, tr_y)\n",
    "    gbr_val = np.expm1(gbr.predict(val_x))\n",
    "    gbr_score = NMAE(val_y, gbr_val)\n",
    "    gbr_nmae.append(gbr_score)\n",
    "    print(f'{gbr.__class__.__name__} Training Completed...NMAE = {NMAE(val_y, gbr_val)}')\n",
    "    \n",
    "    ### CatBoost\n",
    "    cb.fit(tr_data)#, eval_set = val_data, early_stopping_rounds = 750, verbose = 0)\n",
    "    cb_val = np.expm1(cb.predict(val_data))\n",
    "    cb_score = NMAE(val_y, cb_val)\n",
    "    cb_nmae.append(cb_score)\n",
    "    print(f'{cb.__class__.__name__} Training Completed...NMAE = {NMAE(val_y, cb_val)}')\n",
    "    \n",
    "    ### NGBoost\n",
    "    ngb.fit(tr_x, tr_y, val_x, val_y, early_stopping_rounds = 500)\n",
    "    ngb_val = np.expm1(ngb.predict(val_x))\n",
    "    ngb_score = NMAE(val_y, ngb_val)\n",
    "    ngb_nmae.append(ngb_score)\n",
    "    print(f'{ngb.__class__.__name__} Training Completed...NMAE = {NMAE(val_y, ngb_val)}')\n",
    "    \n",
    "    ### XGBoost\n",
    "    xgb.fit(tr_x, tr_y, eval_set = [(tr_x, tr_y), (val_x, val_y)], early_stopping_rounds = 500, verbose = 0, eval_metric = 'mae')\n",
    "    xgb_val = np.expm1(xgb.predict(val_x))\n",
    "    xgb_score = NMAE(val_y, xgb_val)\n",
    "    xgb_nmae.append(xgb_score)\n",
    "    print(f'{xgb.__class__.__name__} Training Completed...NMAE = {NMAE(val_y, xgb_val)}')\n",
    "    \n",
    "    ### Stacking\n",
    "    sr = StackingRegressor(estimators = [('RF', rf), ('CB', cb), ('XGB', xgb), ('GBR', gbr), ('LGBM', lgbm)], final_estimator = rg)\n",
    "    sr.fit(tr_x, tr_y)\n",
    "    sr_val = np.expm1(sr.predict(val_x))\n",
    "    sr_score = NMAE(val_y, sr_val)\n",
    "    sr_nmae.append(sr_score)\n",
    "    print(f'{sr.__class__.__name__} Training Completed...NMAE = {sr_score}\\n')\n",
    "    \n",
    "    ### Make ensemble for validation\n",
    "    val_pred = (sr_val * 0.5 + gbr_val * 0.06 + rf_val * 0.1  + cb_val * 0.2 + ngb_val * 0.1 + xgb_val * 0.04)\n",
    "    fold_nmae = NMAE(val_y, val_pred)\n",
    "    val_nmae.append(fold_nmae)\n",
    "    print(f'********** When Ensemble, {n + 1} FOLD Validation NMAE = {fold_nmae} **********\\n')\n",
    "    \n",
    "    ### Prediction\n",
    "    rf_fold = rf.predict(target) / kf.n_splits\n",
    "    cb_fold = cb.predict(target_data) / kf.n_splits\n",
    "    ngb_fold = ngb.predict(target) / kf.n_splits\n",
    "    xgb_fold = xgb.predict(target) / kf.n_splits\n",
    "    gbr_fold = gbr.predict(target) / kf.n_splits\n",
    "    sr_fold = sr.predict(target) / kf.n_splits\n",
    "    \n",
    "    ### Make ensemble for prediction using test data\n",
    "    fold_pred += (sr_fold * 0.5 + gbr_fold * 0.06 + rf_fold * 0.1  + cb_fold * 0.2 + ngb_fold * 0.1 + xgb_fold * 0.04)\n",
    "    \n",
    "print(f'*-*-*-*-*-*-*-*-*-Training & Prediction Done.....-*-*-*-*-*-*-*-*-*')\n",
    "print(f'Result : {kf.n_splits} FOLD Mean of NMAE = {np.mean(val_nmae)} & std = {np.std(val_nmae)}')\n",
    "print(f'##### Average NMAE of Each Model #####')\n",
    "print(f'{rf.__class__.__name__} = {np.mean(rf_nmae)}')\n",
    "print(f'{cb.__class__.__name__} = {np.mean(cb_nmae)}')\n",
    "print(f'{ngb.__class__.__name__} = {np.mean(ngb_nmae)}')\n",
    "print(f'{gbr.__class__.__name__} = {np.mean(gbr_nmae)}')\n",
    "print(f'{xgb.__class__.__name__} = {np.mean(xgb_nmae)}')\n",
    "print(f'{sr.__class__.__name__} = {np.mean(sr_nmae)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "41ae54d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['target'] = np.expm1(fold_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8cfe3d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('20220204.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "82df4194",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>327868.490767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>128105.089789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>180720.513751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>243449.384776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>132904.980494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1345</th>\n",
       "      <td>1346</td>\n",
       "      <td>342573.258506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1346</th>\n",
       "      <td>1347</td>\n",
       "      <td>125931.246181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1347</th>\n",
       "      <td>1348</td>\n",
       "      <td>68666.944478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1348</th>\n",
       "      <td>1349</td>\n",
       "      <td>186039.292738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1349</th>\n",
       "      <td>1350</td>\n",
       "      <td>128780.451977</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1350 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id         target\n",
       "0        1  327868.490767\n",
       "1        2  128105.089789\n",
       "2        3  180720.513751\n",
       "3        4  243449.384776\n",
       "4        5  132904.980494\n",
       "...    ...            ...\n",
       "1345  1346  342573.258506\n",
       "1346  1347  125931.246181\n",
       "1347  1348   68666.944478\n",
       "1348  1349  186039.292738\n",
       "1349  1350  128780.451977\n",
       "\n",
       "[1350 rows x 2 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b71462",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
